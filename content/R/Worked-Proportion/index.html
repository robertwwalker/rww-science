---
title: "Working an Example on Proportions"
author: 'Robert W. Walker'
date: '2019-10-20'
header:
  caption: ''
  image: ''
  preview: yes
---



<div id="a-proportions-example" class="section level2">
<h2>A Proportions Example</h2>
<p>We started with an equation:</p>
<p><span class="math display">\[ z = \frac{\hat{\pi} - \pi}{\sqrt{\frac{\pi(1-\pi)}{n}}} \]</span></p>
<p>In language, the difference between the sample proportion (recall that with only two outcomes the sample proportion <span class="math inline">\(\hat{\pi}\)</span> is between 0 [all No’s] and 1 [all Yes’s]) and the <em>true probability</em> <span class="math inline">\(\pi\)</span> divided by the standard error of the proportion <span class="math inline">\(\sqrt{\frac{\pi(1-\pi)}{n}}\)</span> has a <span class="math inline">\(z\)</span> [Normal(0,1)] distribution under the condition that <span class="math inline">\(n\pi &gt; 10\)</span> and <span class="math inline">\(n(1-\pi) &gt; 10\)</span>. I will show the left hand side: <span class="math inline">\(z\)</span>.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01), y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Standard Normal Density&quot;, ylab=&quot;f(z)&quot;)
plot(x=seq(-4,4, by=0.01), y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Cumulative Standard Normal&quot;, ylab=&quot;Pr(Z &lt; z)&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Now let’s take a step to put it in the metric of probability. The equation needs a probability on the left and right hand sides. On the right, a probability minus a probability has to have that metric. On the left, we have multiplied both sides by <span class="math inline">\(\sqrt{\frac{\pi(1-\pi)}{n}}\)</span> [which is the square root of the product of two probabilities divided by the sample size so it has metric probability]. That gives us,</p>
<p><span class="math display">\[  z(\sqrt{\frac{\pi(1-\pi)}{n}}) = \hat{\pi} - \pi. \]</span>
We can read this as z [with metric standard errors] times the standard error of the probability is equal to the difference between the sample estimate and the true probability. To be concrete in an example, let’s take the example of 51 supporters of a mayor out of 100 surveyed. That let’s us calculate the full left hand side; this is often known as the margin of error (MOE). We can show it’s distribution for this example. <span class="math display">\[ \sqrt{\frac{.51(1-.51)}{100}} = 0.05 \]</span> Apply that to the plot.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01)*0.05, y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;MOE&quot;, main=&quot;Margin of Error for 51 of 100&quot;, ylab=&quot;f(MOE)&quot;)
plot(x=seq(-4,4, by=0.01)*0.05, y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;MOE&quot;, main=&quot;Cumulative MOE for 51 of 100&quot;, ylab=&quot;Pr(=&lt; MOE)&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/MOE-1.png" width="672" /></p>
</div>
<div id="a-confidence-interval" class="section level2">
<h2>A Confidence Interval</h2>
<p>Now we need one more concrete piece. With what probability do we wish to characterize the underlying level of support [the probability of <code>Support</code>]. Let’s arbitrarily take 95%. The empirical rule says that is plus or minus 2 standard deviations/errors [it is precisely 1.96]. To see that, we will get two vertical[horizontal] lines in the left[right] plot.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01)*0.05, y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;MOE&quot;, main=&quot;95% Margin of Error for 51 of 100&quot;, ylab=&quot;f(MOE)&quot;)
abline(v=qnorm(c(0.025,0.975))*0.05, col=&quot;red&quot;)
plot(x=seq(-4,4, by=0.01)*0.05, y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;MOE&quot;, main=&quot;95% MOE for 51 of 100&quot;, ylab=&quot;Pr(=&lt; MOE)&quot;)
abline(h=c(0.025,0.975), col=&quot;red&quot;)
abline(v=qnorm(c(0.025,0.975))*0.05, col=&quot;red&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/MOE3-1.png" width="672" /></p>
<p>With 95% confidence, the difference between the sample and <em>true</em> probability given 51 out of 100 ranges plus or minus 0.098.</p>
</div>
<div id="our-best-guess-is-the-sample-proportion" class="section level2">
<h2>Our best guess is the sample proportion</h2>
<p>To solve for the <em>true</em> probability, we can write the distribution</p>
<p><span class="math display">\[  \pi = \hat{\pi} - z(\sqrt{\frac{\pi(1-\pi)}{n}}) = \hat{\pi}. \]</span></p>
<p>Finally, we can say that, with 95% confidence, the <em>true</em> probability ranges between 0.412 and 0.608 because 51 of 100 plus or minus 0.098 gives us those boundaries. Let’s show the distribution.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=0.51-seq(-4,4, by=0.01)*0.05, y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=expression(paste(pi)), main=&quot;95% CI for 51 of 100&quot;, ylab=&quot;f(pi)&quot;)
abline(v=0.51-qnorm(c(0.025,0.975))*0.05, col=&quot;red&quot;)
plot(x=0.51+seq(-4,4, by=0.01)*0.05, y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=expression(paste(pi)), main=&quot;95% CI for 51 of 100&quot;, ylab=&quot;Pr(=&lt; pi)&quot;)
abline(h=c(0.025,0.975), col=&quot;red&quot;)
abline(v=0.51-qnorm(c(0.025,0.975))*0.05, col=&quot;red&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/MOE2-1.png" width="672" /></p>
</div>
<div id="an-hypothesis-test" class="section level2">
<h2>An Hypothesis Test?</h2>
<p>If we are willing to claim that the <em>true</em> probability <span class="math inline">\(\pi\)</span> is equal to some value, then we can combine that with the sample proportion to ask <code>how likely are the data given what we claim?</code> What changes from the previous?</p>
<p>Two things. Because we are making a claim about the true value, we will have to substitute that into the formula for the standard error [it is a function of <span class="math inline">\(\pi\)</span>] and into the value in the numerator. Second, we will need to set a rule for deciding that something is implausible enough to conclude that our hypothesis is unsustainable given the data.</p>
<p><span class="math display">\[ z = \frac{\hat{\pi} - \pi}{\sqrt{\frac{\pi(1-\pi)}{n}}} \]</span></p>
<p>To plot this, let’s go back the first plot.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01), y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Standard Normal Density&quot;, ylab=&quot;f(z)&quot;)
plot(x=seq(-4,4, by=0.01), y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Cumulative Standard Normal&quot;, ylab=&quot;Pr(Z &lt; z)&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>The metric here is the standard error. The way to think about it is: if I saw a sample proportion that was <span class="math inline">\(z\)</span> standard errors from my hypothesis, I would conclude that I was wrong. In classical statistics language, we have a significance level that preordains how unlikely the sample value must be to reject our claim. A significance level of 5% would mean that we will make this judgement if the probability is less than 0.05. Where that 0.05 is located forms the final key question. Suppose we wanted to evaluate our hypothesis against an alternative that it could be either bigger or smaller; that would place 0.05/2 or 0.025 probability in each tail of the z above. I show this below.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01), y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Standard Normal Density&quot;, ylab=&quot;f(z)&quot;)
abline(v=qnorm(c(0.025,0.975)), col=&quot;red&quot;)
plot(x=seq(-4,4, by=0.01), y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Cumulative Standard Normal&quot;, ylab=&quot;Pr(Z &lt; z)&quot;)
abline(v=qnorm(c(0.025,0.975)), col=&quot;red&quot;)
abline(h=c(0.025,0.975), col=&quot;red&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>In language, we would reject any claim that is more the 1.96<span class="math inline">\(\approx 2\)</span> standard errors away from the sample value. But this is often not the real question. I don’t want to know if my hypothesis can withstand scrutiny against alternatives both above and below; I more often have a direction in mind. For elections, I would like to rule out 0.5 – a tie – in favor of a win [the probability is greater than 0.5]. To consider that question, I need only focus on the 0.05 probability in the lower or upper tail.</p>
</div>
<div id="whats-a-p-value" class="section level2">
<h2>What’s a p-value?</h2>
<p>To define this, I am going to need a bit more specificity again, I need to define my hypothesis on <span class="math inline">\(\pi\)</span>. First, let’s examine the claim that <span class="math inline">\(\pi = 0.5\)</span> against an alternative that <span class="math inline">\(\pi \neq 0.5\)</span>.</p>
<p><span class="math display">\[ z = \frac{\hat{\pi} - \pi}{\sqrt{\frac{\pi(1-\pi)}{n}}} \]</span></p>
<p>in the abstract and, in the example, we obtain:</p>
<p><span class="math display">\[ z = \frac{0.51 - 0.5}{\sqrt{\frac{0.5(1-0.5)}{100}}} \]</span></p>
<pre class="r"><code>(0.51 - 0.5)/sqrt(0.5*0.5/100)</code></pre>
<pre><code>## [1] 0.2</code></pre>
<p>How likely I am to see something that is 0.2 standard errors [or more] above and below my claim?</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01), y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Standard Normal Density&quot;, ylab=&quot;f(z)&quot;)
abline(v=c(-0.2,0.2), col=&quot;red&quot;)
polygon(x=c(-4,seq(-4,-0.2, by=0.01)), y=c(dnorm(seq(-4,-0.2, by=0.01)), 0), col=&quot;green&quot;)
polygon(x=c(seq(0.2, 4, by=0.01), 4), y=c(0,dnorm(seq(0.2,4, by=0.01))), col=&quot;green&quot;)
plot(x=seq(-4,4, by=0.01), y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Cumulative Standard Normal&quot;, ylab=&quot;Pr(Z &lt; z)&quot;)
abline(v=c(-0.2,0.2), col=&quot;red&quot;)
abline(h=c(pnorm(c(-0.2,0.2))), col=&quot;green&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>That’s the area below -0.2 and above 0.2, or</p>
<pre class="r"><code>pnorm(-0.2)+1-pnorm(0.2)</code></pre>
<pre><code>## [1] 0.8414806</code></pre>
<pre class="r"><code>prop.test(51,100, correct=FALSE)</code></pre>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  51 out of 100, null probability 0.5
## X-squared = 0.04, df = 1, p-value = 0.8415
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4134801 0.6057800
## sample estimates:
##    p 
## 0.51</code></pre>
<p>0.51 is too close to 0.5 with this size of sample to conclude that the <em>true</em> probability isn’t 0.5. Note the use of <code>correct=FALSE</code>. The binomial is discrete and we are approximating it with a normal, there is a famous correction to better approximate continuity that is the default in <em>R</em>. The statistic that <em>R</em> reports is <span class="math inline">\(\chi^2\)</span> – a squared normal or the square of our <span class="math inline">\(z\)</span>.</p>
</div>
<div id="directional-claims" class="section level1">
<h1>Directional Claims</h1>
<p>Now we only place the <span class="math inline">\(z\)</span> we obtained on the graph. Let’s look at the two directions we could examine. Is the <em>true</em> probability 0.5 or greater, compared to less? If it is less, we would expect the sample data to be below the claim. Here, it is not, but the p-value will simply measure all of the probability up to the <span class="math inline">\(z\)</span> we obtained: 0.2.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01), y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Standard Normal Density&quot;, ylab=&quot;f(z)&quot;)
abline(v=c(0.2), col=&quot;red&quot;)
polygon(x=c(-4,seq(-4,0.2, by=0.01)), y=c(dnorm(seq(-4,0.2, by=0.01)), 0), col=&quot;purple&quot;)
plot(x=seq(-4,4, by=0.01), y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Cumulative Standard Normal&quot;, ylab=&quot;Pr(Z &lt; z)&quot;)
abline(v=c(0.2), col=&quot;red&quot;)
abline(h=pnorm(0.2), col=&quot;purple&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>That’s quite likely.</p>
<pre class="r"><code>pnorm(0.2)</code></pre>
<pre><code>## [1] 0.5792597</code></pre>
<pre class="r"><code>prop.test(51,100, correct=FALSE, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  51 out of 100, null probability 0.5
## X-squared = 0.04, df = 1, p-value = 0.5793
## alternative hypothesis: true p is less than 0.5
## 95 percent confidence interval:
##  0.000000 0.590873
## sample estimates:
##    p 
## 0.51</code></pre>
<p>Were we to instead evaluate the claim that it is 0.5 against the alternative that it is greater, we want the upper tail probability of 0.2.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(x=seq(-4,4, by=0.01), y=dnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Standard Normal Density&quot;, ylab=&quot;f(z)&quot;)
abline(v=c(0.2), col=&quot;red&quot;)
polygon(x=c(seq(0.2, 4, by=0.01), 4), y=c(0,dnorm(seq(0.2,4, by=0.01))), col=&quot;magenta&quot;)
plot(x=seq(-4,4, by=0.01), y=pnorm(seq(-4,4, by=0.01)), type=&quot;l&quot;, xlab=&quot;z&quot;, main=&quot;Cumulative Standard Normal&quot;, ylab=&quot;Pr(Z &lt; z)&quot;)
abline(v=c(0.2), col=&quot;red&quot;)
abline(h=pnorm(0.2), col=&quot;magenta&quot;)</code></pre>
<p><img src="/R/Worked-Proportion/index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>1-pnorm(0.2)</code></pre>
<pre><code>## [1] 0.4207403</code></pre>
<pre class="r"><code>prop.test(51,100, correct=FALSE, alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  51 out of 100, null probability 0.5
## X-squared = 0.04, df = 1, p-value = 0.4207
## alternative hypothesis: true p is greater than 0.5
## 95 percent confidence interval:
##  0.4286002 1.0000000
## sample estimates:
##    p 
## 0.51</code></pre>
</div>
