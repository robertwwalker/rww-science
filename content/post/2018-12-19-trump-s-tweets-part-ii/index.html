---
title: Trump's Tweets, Part II
author: RWW
date: '2018-12-19'
slug: trump-s-tweets-part-ii
categories:
  - R
  - twitter
  - tidytext
tags:
  - R
  - R Markdown
  - tidytext
  - twitter sentiment
header:
  caption: ''
  image: ''
---



<div id="trumps-tone" class="section level1">
<h1>Trump’s Tone</h1>
<p>A cool post on sentiment analysis can be found <a href="http://dataaspirant.com/2018/03/22/twitter-sentiment-analysis-using-r/">here</a>. I will now get at the time series characteristics of his tweets and the sentiment stuff.</p>
<p>I start by loading the tmls object that I created <a href="https://rww.science/post/trump-tweet-word-clouds/">in the previous post</a>.</p>
<div id="trumps-overall-tweeting" class="section level2">
<h2>Trump’s Overall Tweeting</h2>
<p>What does it look like?</p>
<pre class="r"><code>library(tidyverse)
library(tidytext)
library(SnowballC)
library(tm)
library(syuzhet)
library(rtweet)
load(url(&quot;https://github.com/robertwwalker/academic-mymod/raw/master/data/TMLS.RData&quot;))
names(tml.djt)</code></pre>
<pre><code>##  [1] &quot;user_id&quot;                 &quot;status_id&quot;              
##  [3] &quot;created_at&quot;              &quot;screen_name&quot;            
##  [5] &quot;text&quot;                    &quot;source&quot;                 
##  [7] &quot;display_text_width&quot;      &quot;reply_to_status_id&quot;     
##  [9] &quot;reply_to_user_id&quot;        &quot;reply_to_screen_name&quot;   
## [11] &quot;is_quote&quot;                &quot;is_retweet&quot;             
## [13] &quot;favorite_count&quot;          &quot;retweet_count&quot;          
## [15] &quot;hashtags&quot;                &quot;symbols&quot;                
## [17] &quot;urls_url&quot;                &quot;urls_t.co&quot;              
## [19] &quot;urls_expanded_url&quot;       &quot;media_url&quot;              
## [21] &quot;media_t.co&quot;              &quot;media_expanded_url&quot;     
## [23] &quot;media_type&quot;              &quot;ext_media_url&quot;          
## [25] &quot;ext_media_t.co&quot;          &quot;ext_media_expanded_url&quot; 
## [27] &quot;ext_media_type&quot;          &quot;mentions_user_id&quot;       
## [29] &quot;mentions_screen_name&quot;    &quot;lang&quot;                   
## [31] &quot;quoted_status_id&quot;        &quot;quoted_text&quot;            
## [33] &quot;quoted_created_at&quot;       &quot;quoted_source&quot;          
## [35] &quot;quoted_favorite_count&quot;   &quot;quoted_retweet_count&quot;   
## [37] &quot;quoted_user_id&quot;          &quot;quoted_screen_name&quot;     
## [39] &quot;quoted_name&quot;             &quot;quoted_followers_count&quot; 
## [41] &quot;quoted_friends_count&quot;    &quot;quoted_statuses_count&quot;  
## [43] &quot;quoted_location&quot;         &quot;quoted_description&quot;     
## [45] &quot;quoted_verified&quot;         &quot;retweet_status_id&quot;      
## [47] &quot;retweet_text&quot;            &quot;retweet_created_at&quot;     
## [49] &quot;retweet_source&quot;          &quot;retweet_favorite_count&quot; 
## [51] &quot;retweet_retweet_count&quot;   &quot;retweet_user_id&quot;        
## [53] &quot;retweet_screen_name&quot;     &quot;retweet_name&quot;           
## [55] &quot;retweet_followers_count&quot; &quot;retweet_friends_count&quot;  
## [57] &quot;retweet_statuses_count&quot;  &quot;retweet_location&quot;       
## [59] &quot;retweet_description&quot;     &quot;retweet_verified&quot;       
## [61] &quot;place_url&quot;               &quot;place_name&quot;             
## [63] &quot;place_full_name&quot;         &quot;place_type&quot;             
## [65] &quot;country&quot;                 &quot;country_code&quot;           
## [67] &quot;geo_coords&quot;              &quot;coords_coords&quot;          
## [69] &quot;bbox_coords&quot;             &quot;status_url&quot;             
## [71] &quot;name&quot;                    &quot;location&quot;               
## [73] &quot;description&quot;             &quot;url&quot;                    
## [75] &quot;protected&quot;               &quot;followers_count&quot;        
## [77] &quot;friends_count&quot;           &quot;listed_count&quot;           
## [79] &quot;statuses_count&quot;          &quot;favourites_count&quot;       
## [81] &quot;account_created_at&quot;      &quot;verified&quot;               
## [83] &quot;profile_url&quot;             &quot;profile_expanded_url&quot;   
## [85] &quot;account_lang&quot;            &quot;profile_banner_url&quot;     
## [87] &quot;profile_background_url&quot;  &quot;profile_image_url&quot;</code></pre>
<pre class="r"><code>ts_plot(tml.djt, &quot;days&quot;) +
  ggplot2::theme_minimal() +
  ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;)) +
  ggplot2::labs(
    x = NULL, y = NULL,
    title = &quot;Frequency of @realDonaldTrump tweets and retweeets&quot;,
    subtitle = &quot;Twitter status (tweet) counts aggregated using days&quot;,
    caption = &quot;\nSource: Data collected from Twitter&#39;s REST API via rtweet&quot;
  )</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
</div>
<div id="trumps-tweets-by-day" class="section level2">
<h2>Trump’s Tweets by Day</h2>
<p>I want to first get rid of retweets to render President Trump in his own voice.</p>
<pre class="r"><code>DJTDF &lt;- tml.djt %&gt;% filter(is_retweet==FALSE)
ts_plot(DJTDF, &quot;days&quot;) +
  ggplot2::theme_minimal() +
  ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;)) +
  ggplot2::labs(
    x = NULL, y = NULL,
    title = &quot;Frequency of @realDonaldTrump tweets [retweeets removed]&quot;,
    subtitle = &quot;Twitter status (tweet) counts aggregated using days&quot;,
    caption = &quot;\nSource: Data collected from Twitter&#39;s REST API via rtweet&quot;
  )</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Some more stuff from <a href="https://stackoverflow.com/questions/31348453/how-do-i-clean-twitter-data-in-r">stack overflow</a>. There is quite a bit of code in here. I simply wrote a function that takes an input character string and cleans it up. Uncomment the various components and pipe them. The sequencing is important and I found this to get everything that I wanted.</p>
<pre class="r"><code>library(RColorBrewer)
TDF &lt;- DJTDF %&gt;% select(text)
library(tidyr)
CT &lt;- TDF %&gt;% mutate(tweetno= row_number())
# TDF contains the text of tweets amd the id
library(stringr)
tweet_cleaner &lt;- function(text) {
  temp1 &lt;- str_replace_all(text, &quot;&amp;amp&quot;, &quot;&quot;) %&gt;% 
    str_replace_all(., &quot;https.*&quot;,&quot;&quot;) %&gt;%
#    str_replace_all(., &quot;http.*&quot;, &quot;&quot;) %&gt;%
    str_replace_all(.,&quot;@[a-z,A-Z]*&quot;,&quot;&quot;)
#    str_replace_all(., &quot;[[:punct:]]&quot;, &quot;&quot;)  
#    str_replace_all(., &quot;[[:digit:]]&quot;, &quot;&quot;) %&gt;%
#    str_replace_all(., &quot;[ \t]{2,}&quot;, &quot;&quot;) %&gt;%
#    str_replace_all(., &quot;^\\s+|\\s+$&quot;, &quot;&quot;)  %&gt;%
#    str_replace_all(., &quot; &quot;,&quot; &quot;) %&gt;%
#    str_replace_all(.,&quot;RT @[a-z,A-Z]*: &quot;,&quot;&quot;) %&gt;% 
#    str_replace_all(.,&quot;#[a-z,A-Z]*&quot;,&quot;&quot;)
  return(temp1)
}
clean_tweets &lt;- data.frame(text=sapply(1:dim(TDF)[[1]], function(x) {tweet_cleaner(TDF[x,&quot;text&quot;])}))
clean_tweets$text &lt;- as.character(clean_tweets$text)
clean_tweets$created_at &lt;- DJTDF$created_at
Trumps.Sent.Words &lt;- clean_tweets %&gt;% unnest_tokens(., word, text) %&gt;% anti_join(stop_words, &quot;word&quot;)
# word.df &lt;- as.vector(TDF)
# emotion.df &lt;- get_nrc_sentiment(word.df)
SNTR1 &lt;- apply(TDF, 1, function(x) {get_nrc_sentiment(x)})
Sent.Res &lt;- bind_rows(SNTR1)
head(Sent.Res)</code></pre>
<pre><code>##   anger anticipation disgust fear joy sadness surprise trust negative positive
## 1     1            1       0    2   2       0        1     4        3        4
## 2     0            2       0    0   2       0        1     2        0        3
## 3     0            1       0    1   1       0        0     1        1        2
## 4     1            1       0    1   0       1        1     0        1        3
## 5     4            1       4    3   0       3        1     1        4        0
## 6     3            0       4    2   0       3        1     1        4        1</code></pre>
</div>
</div>
<div id="a-single-number-sentiment" class="section level1">
<h1>A Single Number Sentiment</h1>
<pre class="r"><code>library(tidytext)
SNTRB &lt;- apply(TDF, 1, function(x) {get_sentiment(x, method=&quot;bing&quot;)})
DJTDF$Bing &lt;- SNTRB
DJTDF &lt;- DJTDF %&gt;% mutate(RN=row_number())
DJTDF &lt;- DJTDF
DJTDF &lt;- DJTDF[order(DJTDF$RN, decreasing = T),]
library(tibbletime)</code></pre>
<pre><code>## 
## Attaching package: &#39;tibbletime&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre class="r"><code>DJTDF_tbl_time_d &lt;- DJTDF %&gt;%
     as_tbl_time(index = created_at) 
My.Res &lt;- DJTDF_tbl_time_d %&gt;%
    collapse_by(&quot;daily&quot;) %&gt;%
    dplyr::group_by(created_at) %&gt;%
    dplyr::summarise_if(is.numeric, mean) %&gt;% select(created_at,Bing)
SBP &lt;- My.Res %&gt;% filter(Bing&gt;0)
SBN &lt;- My.Res %&gt;% filter(Bing&lt;0)
plot(My.Res, type=&quot;l&quot;, xlab=&quot;2018&quot;, ylab=&quot;Avg. Bing Sentiment&quot;, main=&quot;Trump&#39;s Bing Daily Mood&quot;)
points(SBP, col=&quot;green&quot;)
points(SBN, col=&quot;red&quot;)
text(My.Res[316,], &quot;GHW Bush Passes&quot;, cex=0.6)
text(My.Res[66,], &quot;March for Our Life&quot;, cex=0.6)</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>table(sign(My.Res$Bing))</code></pre>
<pre><code>## 
##  -1   0   1 
##  84  16 231</code></pre>
<p>That’s pretty interesting. There are considerably more positive days than negative ones. The timing of the maximum and minimum are fairly clear in time. Some changes the tidytext and licenses for sentiments broke this. To fix it, I have to save a local.</p>
<pre class="r"><code>tidy.tweets &lt;- DJTDF %&gt;% select(created_at, text) %&gt;% unnest_tokens(word, text)
afinn &lt;- tidy.tweets %&gt;% 
  inner_join(get_sentiments(&quot;afinn&quot;)) %&gt;% 
  group_by(created_at) %&gt;% 
  summarise(sentiment = sum(value)) %&gt;% 
  mutate(method = &quot;AFINN&quot;)
bing_and_nrc &lt;- bind_rows(tidy.tweets %&gt;% 
                            inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
                            mutate(method = &quot;Bing&quot;),
                          tidy.tweets %&gt;% 
                            inner_join(get_sentiments(&quot;nrc&quot;) %&gt;% 
                                         filter(sentiment %in% c(&quot;positive&quot;, 
                                                                 &quot;negative&quot;))) %&gt;%
                            mutate(method = &quot;NRC&quot;)) %&gt;%
  count(method, created_at, sentiment) %&gt;%
  spread(sentiment, n, fill = 0) %&gt;%
  mutate(sentiment = positive - negative) %&gt;% select(created_at, sentiment, method)
Sents.Me &lt;- bind_rows(afinn,bing_and_nrc)
SME_tbl_time_d &lt;- Sents.Me  %&gt;% as_tbl_time(index = created_at) 
My.Res &lt;- SME_tbl_time_d %&gt;% group_by(method) %&gt;%
    collapse_by(&quot;daily&quot;) %&gt;%
    dplyr::group_by(created_at, method) %&gt;%
    dplyr::summarise_if(is.numeric, mean) %&gt;% ungroup()
save(Sents.Me,SME_tbl_time_d,My.Res,bing_and_nrc,tidy.tweets, file=&quot;~/TrumpTweets.RData&quot;)</code></pre>
<pre class="r"><code>load(&quot;TrumpTweets.RData&quot;)
ggplot(data = My.Res) +
  aes(x = created_at, y = sentiment, color = method) +
  geom_line() +
  theme_minimal()</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div id="averaging-three-types-of-scaled-sentiments" class="section level2">
<h2>Averaging three types of scaled sentiments</h2>
<pre class="r"><code>MRS &lt;- My.Res %&gt;% group_by(method) %&gt;% mutate(SS=scale(sentiment))
MRS2 &lt;- MRS %&gt;%  collapse_by(&quot;daily&quot;) %&gt;% select(created_at, SS) %&gt;%
    dplyr::group_by(created_at) %&gt;%
    dplyr::summarise_if(is.numeric, mean) </code></pre>
<pre><code>## Adding missing grouping variables: `method`</code></pre>
<pre class="r"><code>ggplot(data = MRS2) +
  aes(x = created_at, y = SS) +
  geom_line(color = &#39;#781c6d&#39;) +
  labs(title = &#39;Sentiment: Averaged&#39;,
    x = &#39;Date&#39;,
    y = &#39;Mean Scaled Sentiment&#39;) +
  theme_minimal()</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="common-words" class="section level2">
<h2>Common Words</h2>
<p>The <code>comparson_cloud()</code> features in <code>wordcloud</code> allow a split of the most common words in the positive and negative sentiment dictionaries.</p>
<pre class="r"><code>library(wordcloud)
library(reshape2)</code></pre>
<pre><code>## 
## Attaching package: &#39;reshape2&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     smiths</code></pre>
<pre class="r"><code>tidy.tweets %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
  count(word, sentiment, sort = TRUE) %&gt;%
  acast(word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;%
  comparison.cloud(colors = c(&quot;red&quot;,&quot;green&quot;),
                   max.words = 100)</code></pre>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="networks" class="section level2">
<h2>Networks</h2>
<pre class="r"><code>library(dplyr)
library(tidyr)
library(tidytext)
library(ggplot2)
library(igraph)</code></pre>
<pre><code>## 
## Attaching package: &#39;igraph&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     as_data_frame, groups, union</code></pre>
<pre><code>## The following objects are masked from &#39;package:purrr&#39;:
## 
##     compose, simplify</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     crossing</code></pre>
<pre><code>## The following object is masked from &#39;package:tibble&#39;:
## 
##     as_data_frame</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     decompose, spectrum</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     union</code></pre>
<pre class="r"><code>library(ggraph)

count_bigrams &lt;- function(dataset) {
  dataset %&gt;%
    unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;%
    separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %&gt;%
    count(word1, word2, sort = TRUE)
}

visualize_bigrams &lt;- function(bigrams) {
  set.seed(2016)
  a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;))
  bigrams %&gt;%
    graph_from_data_frame() %&gt;%
    ggraph(layout = &quot;fr&quot;) +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) +
    geom_node_point(color = &quot;lightblue&quot;, size = 5) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
    theme_void()
}
library(stringr)

djt_bigrams &lt;- clean_tweets %&gt;% select(created_at, text) %&gt;% 
  count_bigrams()

# filter out rare combinations, as well as digits
djt_bigrams %&gt;%
  filter(n &gt; 20,
         !str_detect(word1, &quot;\\d&quot;),
         !str_detect(word2, &quot;\\d&quot;)) %&gt;%
  visualize_bigrams()</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>clean_tweets$RN &lt;- DJTDF$RN
tidy.tweets.RN &lt;- clean_tweets %&gt;% select(RN, text) %&gt;% unnest_tokens(word, text) %&gt;%
  anti_join(stop_words) %&gt;%
  count(RN, word, sort = TRUE) %&gt;%
  ungroup()</code></pre>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre class="r"><code>tweets_dtm &lt;- tidy.tweets.RN %&gt;%
  cast_dtm(RN, word, n)
library(topicmodels)
tweets_lda &lt;- LDA(tweets_dtm, k = 7, control = list(seed = 12345))
tweet_topics &lt;- tidy(tweets_lda, matrix=&quot;beta&quot;)
top_terms &lt;- tweet_topics %&gt;% group_by(topic) %&gt;% top_n(10, beta) %&gt;%
    ungroup() %&gt;%
    arrange(topic, -beta)
top_terms %&gt;%
    mutate(term = reorder(term, beta)) %&gt;%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = &quot;free&quot;) +
    coord_flip()</code></pre>
<p><img src="/post/2018-12-19-trump-s-tweets-part-ii/index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>tweet_topicM &lt;- tidy(tweets_lda, matrix=&quot;gamma&quot;)
top_tweets &lt;- tweet_topicM %&gt;% group_by(topic) %&gt;% top_n(10, gamma) %&gt;%
    ungroup() %&gt;%
    arrange(topic, -gamma)
top_tweets</code></pre>
<pre><code>## # A tibble: 70 x 3
##    document topic gamma
##    &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
##  1 1888         1 0.172
##  2 555          1 0.171
##  3 252          1 0.170
##  4 234          1 0.167
##  5 1830         1 0.166
##  6 1340         1 0.166
##  7 2525         1 0.166
##  8 434          1 0.163
##  9 1101         1 0.162
## 10 399          1 0.162
## # … with 60 more rows</code></pre>
<pre class="r"><code>Tweet.Res &lt;- cbind(TDF[as.numeric(top_tweets$document),],top_tweets)</code></pre>
<p>Mallet is finicky. Below is some playing with it but the stop words are messy.</p>
<pre class="r"><code>library(qdap)
clean_tweets$text &lt;- clean_tweets %&gt;% select(text) %&gt;% rm_stopwords(., tm::stopwords(&quot;english&quot;), separate = FALSE, unlist=FALSE)
library(mallet)
clean_tweets$RN &lt;- as.character(clean_tweets$RN)
clean_tweets &lt;- clean_tweets
# create an empty file of &quot;stopwords&quot;
# file.create(empty_file &lt;- tempfile())
# mystopwords &lt;- as.character(stop_words[,1])
stopwords_en &lt;-  stop_words
#system.file(&quot;stoplists/en.txt&quot;, package = &quot;mallet&quot;)
docs &lt;- mallet.import(clean_tweets$RN, clean_tweets$text, stoplist=stopwords_en)
mallet_model &lt;- MalletLDA(num.topics = 6)
mallet_model$loadDocuments(docs)
mallet_model$train(250)
mallet_model$maximize(100)
topic.words &lt;- mallet.topic.words(mallet_model, smoothed=TRUE, normalized=TRUE)
names(topic.words)
mallet.top.words(mallet_model, word.weights = topic.words[4,], num.top.words = 5)</code></pre>
</div>
<div id="sentiments-and-tidy-calendars" class="section level2">
<h2>Sentiments and Tidy Calendars</h2>
<p>Now I want to play with the time series properties of the tweet sentiments. Days of the week and times of day aggregated over different periods can say something… Perhaps some day?</p>
</div>
</div>
