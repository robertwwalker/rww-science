---
title: "Time Series: A Forecasting Toolbox"
subtitle: "FPP3, Chapter 5"
author: "Robert W. Walker"
institute: "AGSM"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina=3, fig.width=8, fig.height=5, warning=FALSE, message=FALSE)
library(tidyverse)
library(fpp3)
library(purrr)
library(gganimate)
library(tsibble)
options(scipen=9)
library(tidyquant)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringan)
library(xaringanthemer)
style_mono_accent(base_color = "#43418A", text_font_google   = google_font("Roboto Condensed", "300", "300i"))
```

# Colleen's Question

---

# An Overview

---

## Packages

Getting started

```
library(tidyverse)
library(fpp3)
library(purrr)
library(gganimate)
library(seasonal)
<<<<<<< HEAD
library(tidyquant)
library(magrittr)
```
---

# The magic of `forecast`

The method:
1. Tidy  
2. Visualise  
3. Model  
  a. Specify  
  b. Estimate  
  c. Evaluate  
  d. Visualize  
4. Forecast

---
# Four Simple Methods

1. Average  
2. Naive method [Last value]  
3. Naive Seasonal Method  [Last seasonal values]
4. Drift method [Constant rate of change]  

---
# Fits and leftovers

Just as we can decompose a regression into explained and unexplained, we can decompose a time series regression into predicted or fitted and residual variation.

In a regression setting, we might have something like:

$$y = \alpha + \beta x + \epsilon$$
where x and y are observed data, $\alpha$ is an intercept to be estimated, $\beta$ is a slope to be estimated and $\epsilon$ represents the residual.  Rearranging, the fitted/predicted value is 
$$\hat{y} = \hat{\alpha} + x \hat{\beta}$$
and the residual is: 

$$\hat{e} = y - \hat{y}$$ or expanding and distributing:
$$\hat{e} = y - \hat{\alpha} - x \hat{\beta}$$
---
# Diagnostics for residuals

Seek to falsify two desirable characteristics:

1. Residuals should be uncorrelated [remaining time series information] 
2. Residuals should have mean zero [otherwise bias -- systematically wrong].

Additional desiderata include: Constant variance and normalcy though the latter implies the former.

`fable` makes this relatively straightforward with `augment` applied to a `tsibble`.  `tidy` renders details.

---
# Take Ford

```{r}
Ford <- tq_get("F", from="2018-01-01") %>% 
  as_tsibble(index=date) 
Ford %>% autoplot(close)
```

---
# That's Complete, but has missings

```{r}
Clean.Ford <- Ford %>%
  mutate(day = row_number()) %>%
  update_tsibble(index = day, regular = TRUE)
F.Ford <- Clean.Ford %>% filter(date < "2021-02-01")
autoplot(F.Ford, close) +
  labs(x = "Day", y = "Closing Price (US$)",
       title = "Ford since 2018")
```

---
# A Naive Forecast: Fitted values

```{r}
augmented <- F.Ford %>% model(NAIVE(close)) %>% augment()
augmented %>% filter(day > 700) %>% ggplot() + aes(x=day, y=close) + geom_line() + geom_line(aes(y=.fitted), color="red")
```

---
# Residual Plot


```{r}
autoplot(augmented, .innov) +
  labs(x = "Day", y = "Residual",
       title = "Residuals from naïve method")
```

---
# Over time correlations?

This looks pretty good....

```{r}
augmented %>% ACF(.innov) %>% autoplot()
```

---
# THe automagic plot

```{r}
F.Ford %>% model(NAIVE(close)) %>% gg_tsresiduals()
```

---
# A Statistic

Could be white noise [the null hypothesis].....

```{r}
augmented %>% features(.innov, ljung_box, lag = 10, dof = 0)
```
---
# A Random Walk

There's no drift....

```{r}
fit <- F.Ford %>% model(RW(close ~ drift()))
tidy(fit)
```

---
# Assessment

```{r}
F.F2 <- F.Ford %>% model(RW(close ~ drift())) %>% augment()
F.F2 %>% ggplot() + aes(x=day, y=close) + geom_line() + geom_line(aes(y=.fitted), color="red") + geom_line(data=augmented, aes(y=.fitted), color="blue")
```

---
## Intervals and Predictions

Two forms: 
1. Parametric: Assume a distribution for $e$.
2. Simulation: the bootstrap [using residuals]

---
# Parametric

Note the tiny negative drift....

```{r}
F.Ford %>%
  model(`Naive` = NAIVE(close), 
        `RW` = RW(close ~ drift())) %>%
  forecast(h = 30) %>% autoplot() + guides(level=FALSE)
```

---
# Bootstrap

```{r}
F.Ford %>%
  model(`Naive` = NAIVE(close), 
        `RW` = RW(close ~ drift())) %>%
  forecast(h = 30, times=5, bootstrap=TRUE) %>% autoplot() + guides(level=FALSE)
```

---
# More Resamples make them smoother

```{r}
F.Ford %>%
  model(`Naive` = NAIVE(close), 
        `RW` = RW(close ~ drift())) %>%
  forecast(h = 30, times=500, bootstrap=TRUE) %>% autoplot() + guides(level=FALSE)
```

# Transformations and Forecasts

Are handled automagically by `fable` as long as they are a part of the workflow in the beginning of the chapter.

```{r}
F.Ford %>%
  model(`Naive` = NAIVE(log(close)), 
        `RW` = RW(log(close) ~ drift())) %>%
  forecast(h = 30) %>% autoplot() + guides(level=FALSE)
```

---
# Training and Test

Creating benchmarks for a forecast by slicing the extant data.

---
# Evaluating Forecasts

Three methods:
1. Points  
2. Distributions  
3. Cross-Validation  

---
# The Metrics

1. Mean Absolute Error [MAE]  
2. Root Mean Square Error [RMSE]
3. Mean Absolute Percentage Error [MAPE]  
4. symmetric Mean Absolute Percentage Error [sMAPE]  
5. Mean Absolute Scaled Error [MASE]
6. Root Mean Squared Scaled Error [RMSSE]

---
# Points

```{r}
Ford.Feb <- Clean.Ford %>% filter(date >= "2020-02-01") %>% as_tsibble(index=day)
ford_fit <- F.Ford %>%
  model(
    Mean = MEAN(close),
    `Naïve` = NAIVE(close),
    Drift = RW(close ~ drift())
  )
Ford.Forecast <- ford_fit %>% forecast(h=10)
```

---
# Assessment of Points

```{r}
Ford.Forecast %>% accuracy(Clean.Ford)
```

---
# Assessing Coverage

Four scores:
1. Quantile  
2. Winkler Scores  
3. Continuous Ranked Probability Scores  
4. Relative Skill Scores  

---
# TSCV

`stretch_tsibble`

```{r}
F.Ford.Training <- F.Ford %>% stretch_tsibble(.init=10, .step=1)
F.Ford.Training %>% model(`RW` = RW(close ~ drift()), `Mean` = NAIVE(close)) %>% forecast(h=1) %>% accuracy(F.Ford)
```
---
# The Forecast Horizon

How bad and how fast?

---
# Chapter 6: Judgemental Forecasts

Are not really why we are here but are common nevertheless....

---
# The Methods

1. Delphi [An Expert Ensemble]
2. Analogies  
3. Scenarios  
4. New things  
5. Adjustment  


